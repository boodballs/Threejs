LLM Evaluation: 3D Web Application Generation Capabilities
Project Overview
This project evaluates the capabilities of nine leading Large Language Models (LLMs) to generate interactive 3D web applications using Three.js. Each model was prompted with identical instructions to create a responsive, device-optimized 3D application. The evaluation provides insights into each model's code generation quality, understanding of Three.js, and ability to implement responsive design principles.

Models Evaluated
Claude 3.7 (Anthropic)
Gemma 3 (Google)
Gemini 2.5 Pro (Google)
Llama 3.1-400B (Meta)
Qwen 2.5 Coder (Alibaba)
GPT-4.1 (OpenAI)
Mistral 2 Large (Mistral AI)
DeepSeek V3 (DeepSeek)
Grok 3 (xAI)
Evaluation Methodology
Prompt Design
A single, carefully crafted prompt was used across all models, requesting:

An interactive 3D web application using Three.js
Responsive design that works across desktop, tablet, and mobile devices
Optimized performance across all device capabilities
Clear, well-commented code with best practices
Evaluation Criteria
Each model's response was evaluated on:

Code Correctness: Does the generated code run without errors?
Three.js Implementation: Proper use of Three.js concepts and APIs
Responsiveness: Adaptation to different screen sizes and device capabilities
Performance Optimization: Efficient rendering and resource management
Code Quality: Organization, comments, and adherence to best practices
Interactive Elements: Implementation of user interaction features
Creative Approach: Novel or interesting implementation approaches
